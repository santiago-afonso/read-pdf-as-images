#!/usr/bin/env bash
set -euo pipefail

# read-pdf
# Unified CLI to:
# - Read PDFs as markdown text via markitdown (fast default) or pymupdf4llm (precise, slow), wrapped in <pdf-metadata> and <pdf-text> pseudo-XML.
# - Emit raw markdown output only (--as-raw-text).
# - Render pages to images (--as-images) and emit a JSONL manifest to stderr.

VERSION="0.1.3"
TOOL_NAME="read-pdf"

SCRIPT_DIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)

# Dependency fetching / cache behavior (uv):
# - Default: online (READ_PDF_UV_OFFLINE=0) so missing deps can be fetched.
# - To force offline (fail-fast, no network), set READ_PDF_UV_OFFLINE=1.
READ_PDF_UV_OFFLINE="${READ_PDF_UV_OFFLINE:-0}"

usage() {
  local script_target=""
  local script_target_line=""
  if command -v readlink >/dev/null 2>&1; then
    script_target=$(readlink "${BASH_SOURCE[0]}" 2>/dev/null || true)
    if [ -n "$script_target" ]; then
      script_target_line=$'  - Script target (symlink): '"$script_target"$'\n'
    fi
  fi

  cat <<USAGE
${TOOL_NAME} — read PDFs as text or images for coding agents

Usage:
  ${TOOL_NAME} <pdf> [--as-text-fast] [--page-structure] [--doc-structure]
  ${TOOL_NAME} <pdf> --as-text-precise-layout-slow [--page-structure] [--doc-structure]
  ${TOOL_NAME} <pdf> --toc [--page-structure] [--doc-structure]
  ${TOOL_NAME} <pdf> --toc-pages
  ${TOOL_NAME} <pdf> --table-pages
  ${TOOL_NAME} <pdf> --chart-pages
  ${TOOL_NAME} <pdf> --search "<regex>"
  ${TOOL_NAME} <pdf> --as-raw-text
  ${TOOL_NAME} <pdf> --as-images [--pages "1,3,7-12"] [--dpi 220] [--format png|jpeg] [--outdir DIR]
  ${TOOL_NAME} --prime-cache
  ${TOOL_NAME} --help | -h
  ${TOOL_NAME} --version | -V

Modes:
  (default) / --as-text-fast  Convert the PDF with markitdown (fast) and emit:
                              - <pdf-metadata> with file identity, tool/conversion info, layout guesses.
                              - <pdf-text> containing markdown output (with a page-count header and PAGE markers).
                              Alias: --as-text
  --as-text-precise-layout-slow  Convert the PDF with pymupdf4llm (layout-aware, can be very slow) and emit:
                                 - <pdf-metadata> with file identity, tool/conversion info, layout guesses.
                                 - <pdf-text> containing markdown output (with a page-count header and PAGE markers).
  --toc                   Best-effort extraction of TOC/Index/List pages (English+Spanish+French) with heuristics
                          (e.g., headings + lines ending in page numbers). Emits the same pseudo-XML wrapper
                          as text mode but caps output to 5 pages. If no matches are found, prints plain
                          guidance text (no pseudo-XML) for the agent to inspect the full document.
  --toc-pages             List pages that might contain TOC/Index/List sections (English+Spanish+French),
                          using best-effort heuristics. Emits JSON to stdout (may include false positives/negatives).
  --table-pages           List pages that might contain tables (Table/Tabla/Tableau/Cuadro + numbering heuristics).
                          Emits JSON to stdout (best-effort; may include false positives/negatives).
  --chart-pages           List pages that might contain charts/figures/graphics (English+Spanish+French + numbering heuristics).
                          Emits JSON to stdout (best-effort; may include false positives/negatives).
  --search                Search the PDF for a regex and emit JSONL (one line per match) with page numbers and
                          ~50 words of context before and after each match (best-effort; extraction/layout may affect matches).
  --as-raw-text           Emit only the raw markdown output (no pseudo-XML).
  --as-images             Render pages to images (Poppler) and emit JSONL to stderr (one line per page).

Optional metadata flags (text mode only):
  --page-structure        Include per-page flags/counts in <pdf-metadata> (has_text, word_count, image_count, table_count).
  --doc-structure         Include doc-level structure in <pdf-metadata> (bookmarks + internal/external link list).

Image options (with --as-images):
  --pages "1,3,7-12"      Comma/range list of 1-based pages. Defaults to all pages.
  --dpi 220               Rendering DPI (passed to pdftoppm). Default: 220.
  --format png|jpeg       Output image format. Default: png. Note: jpeg output files use the .jpg extension.
  --outdir DIR            Output directory. Default: tmp/pdf_renders/<pdf-basename-no-ext>/

Exit codes:
  0  success
  2  usage error (prints this help)
  3+ runtime errors (dependencies, IO, conversions)

Dependency notes:
  - Python deps are fetched on demand via uv.
  - Default behavior is online. To force offline behavior (no network), set:
      READ_PDF_UV_OFFLINE=1
  - To prefetch and warm the cache once (recommended for restricted environments),
    run:
      ${TOOL_NAME} --prime-cache

Operational context:
  - Tool: ${TOOL_NAME} ${VERSION}
  - Script path: ${BASH_SOURCE[0]}
${script_target_line}  - Note: if you installed via 'make install', re-run it after pulling updates (the install target copies files into PREFIX/bin).
  - Text engines:
    - markitdown[pdf] (fast default) via 'uv run --with markitdown[pdf] python scripts/read_pdf_text.py --engine markitdown'
    - pymupdf4llm (precise layout, slow) via 'uv run --with pymupdf4llm python scripts/read_pdf_text.py --engine pymupdf4llm'
  - Search/page listing engine: PyMuPDF via 'uv run --with pymupdf python scripts/read_pdf_search.py' and '.../read_pdf_page_candidates.py'
  - Image engine: pdfinfo + pdftoppm (Poppler)
  - JSONL: in --as-images mode, one line per page is written to stderr. Stdout prints token-estimate totals/averages for gpt-5 and Gemini 3 image inputs.
USAGE
}

err() { echo "ERROR: $*" >&2; }

maybe_print_offline_cache_hint() {
  if [ "${READ_PDF_UV_OFFLINE:-0}" != "0" ]; then
    echo "Hint: running with uv offline (READ_PDF_UV_OFFLINE=1). If dependencies are missing, re-run once with READ_PDF_UV_OFFLINE=0 or run 'read-pdf --prime-cache' in an online environment." >&2
  fi
}

need_cmd() {
  if ! command -v "$1" >/dev/null 2>&1; then
    runtime_err "Missing dependency: $1"
  fi
}

resolve_uv_cache_dir() {
  # Prefer a persistent cache dir (shared across working directories) when possible,
  # but fall back to a workspace-local cache under ./tmp/uv_cache.
  if [ -n "${READ_PDF_UV_CACHE_DIR:-}" ]; then
    printf '%s' "${READ_PDF_UV_CACHE_DIR}"
    return 0
  fi
  if [ -n "${UV_CACHE_DIR:-}" ]; then
    printf '%s' "${UV_CACHE_DIR}"
    return 0
  fi
  if [ -n "${XDG_CACHE_HOME:-}" ]; then
    printf '%s/uv' "${XDG_CACHE_HOME%/}"
    return 0
  fi
  if [ -n "${HOME:-}" ]; then
    printf '%s/.cache/uv' "${HOME%/}"
    return 0
  fi
  printf '%s/tmp/uv_cache' "$PWD"
}

uv_run() {
  local cache_dir
  cache_dir=$(resolve_uv_cache_dir)

  local -a uv_args=()
  if [ "${READ_PDF_UV_OFFLINE:-0}" != "0" ]; then
    uv_args+=(--offline)
  fi

  if mkdir -p "$cache_dir" >/dev/null 2>&1; then
    uv "${uv_args[@]}" --cache-dir "$cache_dir" run "$@"
    return 0
  fi

  # If the preferred cache dir isn't writable (common in sandboxed runs), fall back
  # to a workspace-local cache before giving up on caching entirely.
  local fallback_dir="$PWD/tmp/uv_cache"
  if [ "$cache_dir" != "$fallback_dir" ] && mkdir -p "$fallback_dir" >/dev/null 2>&1; then
    uv "${uv_args[@]}" --cache-dir "$fallback_dir" run "$@"
    return 0
  fi

  uv "${uv_args[@]}" --no-cache run "$@"
}

runtime_err() {
  local msg=$1
  {
    echo "ERROR: ${msg}"
    maybe_print_offline_cache_hint
    echo "Context: tool=${TOOL_NAME} version=${VERSION} mode=${MODE:-unknown} pdf=${PDF:-<none>} engine=${CONVERSION_ENGINE:-<unknown>}"
    echo "Hint: run '${TOOL_NAME} --help' for usage and context."
  } >&2
  exit 3
}

xml_escape() {
  local s=${1-}
  s=${s//&/&amp;}
  s=${s//</&lt;}
  s=${s//>/&gt;}
  s=${s//\"/&quot;}
  s=${s//\'/&apos;}
  printf '%s' "$s"
}

json_escape() {
  local s=${1-}
  s=${s//\\/\\\\}
  s=${s//\"/\\\"}
  s=${s//$'\n'/\\n}
  s=${s//$'\r'/\\r}
  s=${s//$'\t'/\\t}
  printf '%s' "$s"
}

ensure_helper() {
  local path=$1
  local label=${2:-$1}
  if [ ! -f "$path" ]; then
    runtime_err "Missing helper script: ${label} (expected at ${path}). Reinstall via 'make install' to place helper scripts alongside the CLI."
  fi
}

# Globals for parsed PDF info (text and images modes)
PDF=""
PDF_PATH=""
PDF_BASENAME=""
PDF_PAGES=0
PDF_TITLE=""
PDF_AUTHOR=""
PDF_PRODUCER=""
PDF_CREATOR=""
PDF_VERSION=""
PDF_SIZE_BYTES=0
PDF_SIZE_KB=0
PDF_PAGE_W_PTS=""
PDF_PAGE_H_PTS=""

MODE="text"        # text | raw | images
TEXT_ENGINE="markitdown"  # markitdown | pymupdf4llm (text mode only)
PAGE_STRUCTURE=false
DOC_STRUCTURE=false
TOC_MAX_PAGES=5
SEARCH_REGEX=""

# Image mode options
PAGES_SPEC=""
DPI=220
FORMAT="png"
OUTDIR=""

CONVERSION_ENGINE=""
PAGE_STRUCTURE_XML=""
DOC_STRUCTURE_XML=""
TOC_EXTRACTION_XML=""
TOC_MATCHED_PAGES=""

READ_PDF_TEXT_SCRIPT="${SCRIPT_DIR}/read_pdf_text.py"
READ_PDF_STRUCTURE_SCRIPT="${SCRIPT_DIR}/read_pdf_structure.py"
READ_PDF_SEARCH_SCRIPT="${SCRIPT_DIR}/read_pdf_search.py"
READ_PDF_PAGE_CANDIDATES_SCRIPT="${SCRIPT_DIR}/read_pdf_page_candidates.py"

gather_pdf_info() {
  local pdf=$1
  PDF="$pdf"

  # Absolute-ish path without needing realpath
  local dir base
  dir=$(cd "$(dirname "$pdf")" && pwd)
  base=$(basename -- "$pdf")
  PDF_PATH="${dir}/${base}"
  PDF_BASENAME="$base"

  need_cmd pdfinfo
  local info
  if ! info=$(pdfinfo "$pdf" 2>/dev/null); then
    runtime_err "pdfinfo failed for: $pdf"
  fi

  PDF_PAGES=$(printf '%s\n' "$info" | sed -n 's/^Pages:[[:space:]]*//p' | head -n1)
  PDF_TITLE=$(printf '%s\n' "$info" | sed -n 's/^Title:[[:space:]]*//p' | head -n1)
  PDF_AUTHOR=$(printf '%s\n' "$info" | sed -n 's/^Author:[[:space:]]*//p' | head -n1)
  PDF_PRODUCER=$(printf '%s\n' "$info" | sed -n 's/^Producer:[[:space:]]*//p' | head -n1)
  PDF_CREATOR=$(printf '%s\n' "$info" | sed -n 's/^Creator:[[:space:]]*//p' | head -n1)
  PDF_VERSION=$(printf '%s\n' "$info" | sed -n 's/^PDF version:[[:space:]]*//p' | head -n1)

  if ! [[ "$PDF_PAGES" =~ ^[0-9]+$ ]]; then
    runtime_err "Could not determine page count for: $pdf"
  fi

  local page_size
  page_size=$(printf '%s\n' "$info" | sed -n 's/^Page size:[[:space:]]*//p' | head -n1)
  if [ -n "$page_size" ]; then
    PDF_PAGE_W_PTS=$(printf '%s\n' "$page_size" | awk '{print $1}')
    PDF_PAGE_H_PTS=$(printf '%s\n' "$page_size" | awk '{print $3}')
  fi

  local bytes
  bytes=$(wc -c < "$pdf" | tr -d ' ')
  PDF_SIZE_BYTES=${bytes:-0}
  if [[ "$PDF_SIZE_BYTES" =~ ^[0-9]+$ ]]; then
    PDF_SIZE_KB=$(( (PDF_SIZE_BYTES + 1023) / 1024 ))
  else
    PDF_SIZE_BYTES=0
    PDF_SIZE_KB=0
  fi
}

compute_layout_guesses() {
  local char_count=$1

  LAYOUT_GUESS_SLIDE_DECK="false"
  LAYOUT_GUESS_SCANNED="false"
  LAYOUT_GUESS_MULTI_COLUMN="false"

  # Simple heuristics, explicitly labeled as guesses.
  if [[ "$PDF_CREATOR" =~ [Pp]ower[Pp]oint ]] || [[ "$PDF_PRODUCER" =~ [Pp]ower[Pp]oint ]] || [[ "$PDF_BASENAME" =~ [Ss]lides ]] || [[ "$PDF_BASENAME" =~ [Dd]eck ]]; then
    LAYOUT_GUESS_SLIDE_DECK="true"
  fi

  if (( PDF_PAGES > 0 )); then
    local per_page=$(( char_count / PDF_PAGES ))
    # Very low text density per page suggests a scanned document.
    if (( per_page < 50 )); then
      LAYOUT_GUESS_SCANNED="true"
    fi
    # High density could suggest multi-column content; very rough guess.
    if (( per_page > 1200 )); then
      LAYOUT_GUESS_MULTI_COLUMN="true"
    fi
  fi
}

emit_metadata() {
  local char_count=$1

  echo "<pdf-metadata>"
  printf '  <file path="%s" basename="%s" size_bytes="%s" size_kb="%s" />\n' \
    "$(xml_escape "$PDF_PATH")" \
    "$(xml_escape "$PDF_BASENAME")" \
    "$(xml_escape "$PDF_SIZE_BYTES")" \
    "$(xml_escape "$PDF_SIZE_KB")"

  printf '  <document title="%s" author="%s" pages="%s" pdf_version="%s" producer="%s" creator="%s" />\n' \
    "$(xml_escape "$PDF_TITLE")" \
    "$(xml_escape "$PDF_AUTHOR")" \
    "$(xml_escape "$PDF_PAGES")" \
    "$(xml_escape "$PDF_VERSION")" \
    "$(xml_escape "$PDF_PRODUCER")" \
    "$(xml_escape "$PDF_CREATOR")"

  printf '  <conversion tool="%s" tool_version="%s" mode="%s" engine="%s" engine_version="%s" />\n' \
    "$(xml_escape "$TOOL_NAME")" \
    "$(xml_escape "$VERSION")" \
    "$(xml_escape "$MODE")" \
    "$(xml_escape "$CONVERSION_ENGINE")" \
    "unknown"

  compute_layout_guesses "$char_count"
  printf '  <layout-guesses likely_slide_deck="%s" likely_scanned_document="%s" likely_multi_column="%s" note="%s" />\n' \
    "$(xml_escape "$LAYOUT_GUESS_SLIDE_DECK")" \
    "$(xml_escape "$LAYOUT_GUESS_SCANNED")" \
    "$(xml_escape "$LAYOUT_GUESS_MULTI_COLUMN")" \
    "heuristic-only; may be inaccurate"

  if [ "$PAGE_STRUCTURE" = true ]; then
    if [ -n "$PAGE_STRUCTURE_XML" ]; then
      echo "$PAGE_STRUCTURE_XML"
    else
      echo "  <page-structure>"
      local i
      for (( i=1; i<=PDF_PAGES; i++ )); do
        printf '    <page index="%d" />\n' "$i"
      done
      echo "  </page-structure>"
    fi
  fi

  if [ "$DOC_STRUCTURE" = true ]; then
    if [ -n "$DOC_STRUCTURE_XML" ]; then
      echo "$DOC_STRUCTURE_XML"
    else
      printf '  <doc-structure available="false" reason="not-implemented" />\n'
    fi
  fi

  if [ "$MODE" = "toc" ]; then
    if [ -n "$TOC_EXTRACTION_XML" ]; then
      echo "$TOC_EXTRACTION_XML"
    else
      printf '  <toc-extraction best_effort="true" max_pages="%s" matched_pages="%s" note="%s" />\n' \
        "$(xml_escape "$TOC_MAX_PAGES")" \
        "$(xml_escape "$TOC_MATCHED_PAGES")" \
        "heuristic-only; may miss TOC/Index pages (including ones not matched by regex/heuristics)"
    fi
  fi

  echo "</pdf-metadata>"
}

emit_text_block() {
  local tmp_text=$1
  local char_count=$2

  local extra_attrs=""
  if [ "$MODE" = "toc" ]; then
    extra_attrs=$(printf ' filter="%s" best_effort="%s" matched_pages="%s" max_pages="%s"' \
      "toc" \
      "true" \
      "$(xml_escape "$TOC_MATCHED_PAGES")" \
      "$(xml_escape "$TOC_MAX_PAGES")")
  fi

  printf '<pdf-text format="%s" source="%s" lossy="%s" pages="%s" char_count="%s"%s>\n' \
    "markdown" \
    "$(xml_escape "$CONVERSION_ENGINE")" \
    "true" \
    "$(xml_escape "$PDF_PAGES")" \
    "$(xml_escape "$char_count")" \
    "$extra_attrs"
  printf '<![CDATA[\n'
  printf '<!-- ORIGINAL_PAGES=%s; page boundaries are marked with \"<!-- PAGE n -->\" comments inserted by read_pdf_text.py. -->\n' \
    "$PDF_PAGES"
  if [ "$MODE" = "toc" ]; then
    printf '<!-- TOC_EXTRACTION_BEST_EFFORT=true; matched_pages=%s; max_pages=%s; may miss TOC/Index pages, including ones not matched by regex/heuristics. -->\n' \
      "$TOC_MATCHED_PAGES" \
      "$TOC_MAX_PAGES"
  fi
  cat "$tmp_text"
  printf '\n]]>\n'
  printf '</pdf-text>\n'
}

text_mode() {
  CONVERSION_ENGINE="$TEXT_ENGINE"

  [ -f "$PDF" ] || runtime_err "PDF not found: $PDF"

  gather_pdf_info "$PDF"

  need_cmd uv

  # Optional structural enrichment
  if [ "$PAGE_STRUCTURE" = true ] || [ "$DOC_STRUCTURE" = true ]; then
    ensure_helper "$READ_PDF_STRUCTURE_SCRIPT" "read_pdf_structure.py"
    local struct_json
    if ! struct_json=$(uv_run --with pymupdf4llm python "${READ_PDF_STRUCTURE_SCRIPT}" "$PDF"); then
      runtime_err "pymupdf4llm structure scan failed for: $PDF"
    fi

    if [ "$PAGE_STRUCTURE" = true ]; then
      PAGE_STRUCTURE_XML=$(uv_run python - "$struct_json" <<'PY'
import json
import sys

def esc(val: str) -> str:
    return (
        val.replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
        .replace('"', "&quot;")
        .replace("'", "&apos;")
    )

data = json.loads(sys.argv[1])
out = []
out.append("  <page-structure>")
for p in data.get("pages", []):
    idx = p.get("index")
    if idx is None:
        continue
    out.append(
        f'    <page index="{idx}" '
        f'has_text="{str(bool(p.get("has_text"))).lower()}" '
        f'word_count="{p.get("word_count", 0)}" '
        f'image_count="{p.get("image_count", 0)}" '
        f'table_count="{p.get("table_count", 0)}" />'
    )
out.append("  </page-structure>")
print("\n".join(out))
PY
)
    fi

    if [ "$DOC_STRUCTURE" = true ]; then
      DOC_STRUCTURE_XML=$(uv_run python - "$struct_json" <<'PY'
import json
import sys

def esc(val: str) -> str:
    return (
        val.replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
        .replace('"', "&quot;")
        .replace("'", "&apos;")
    )

data = json.loads(sys.argv[1])
out = []
out.append("  <doc-structure>")

out.append("    <bookmarks>")
for b in data.get("bookmarks", []):
    title = esc(str(b.get("title", "")))
    page = b.get("page")
    level = b.get("level")
    if page is None or level is None:
        continue
    out.append(f'      <bookmark title="{title}" page="{page}" level="{level}" />')
out.append("    </bookmarks>")

out.append("    <links>")
for l in data.get("links", []):
    ltype = l.get("type")
    from_page = l.get("from_page")
    if from_page is None or ltype not in {"internal", "external"}:
        continue
    if ltype == "external":
        uri = esc(str(l.get("uri", "")))
        out.append(f'      <link type="external" from_page="{from_page}" uri="{uri}" />')
    elif ltype == "internal":
        to_page = l.get("to_page")
        if to_page is None:
            continue
        out.append(f'      <link type="internal" from_page="{from_page}" to_page="{to_page}" />')
out.append("    </links>")

out.append("  </doc-structure>")
print("\n".join(out))
PY
      )
    fi
  fi

  ensure_helper "$READ_PDF_TEXT_SCRIPT" "read_pdf_text.py"

  local tmpdir
  tmpdir=$(mktemp -d -t read-pdf-text.XXXXXX)
  local tmp_text="${tmpdir}/text.md"
  local tmp_err="${tmpdir}/text.stderr"

  if [ "$TEXT_ENGINE" = "markitdown" ]; then
    # markitdown/pdfminer can emit noisy diagnostics (often benign) to stderr.
    # Keep stdout clean (pseudo-XML only) by capturing stderr and only surfacing
    # it if the conversion fails.
    if ! uv_run --with 'markitdown[pdf]' python "${READ_PDF_TEXT_SCRIPT}" \
      --engine markitdown \
      --expected-pages "$PDF_PAGES" \
      "$PDF" >"$tmp_text" 2>"$tmp_err"; then
      if [ -s "$tmp_err" ]; then
        echo "Underlying engine stderr (markitdown):" >&2
        cat "$tmp_err" >&2
      fi
      runtime_err "markitdown (via uv) failed for: $PDF"
    fi
  else
    if ! uv_run --with pymupdf4llm python "${READ_PDF_TEXT_SCRIPT}" \
      --engine pymupdf4llm \
      --expected-pages "$PDF_PAGES" \
      "$PDF" >"$tmp_text"; then
      runtime_err "pymupdf4llm (via uv) failed for: $PDF"
    fi
  fi

  local char_count
  char_count=$(wc -c < "$tmp_text" | tr -d ' ')
  emit_metadata "$char_count"
  emit_text_block "$tmp_text" "$char_count"
  rm -rf "$tmpdir"
}

toc_mode() {
  CONVERSION_ENGINE="pymupdf4llm"
  MODE="toc"

  [ -f "$PDF" ] || runtime_err "PDF not found: $PDF"

  gather_pdf_info "$PDF"

  need_cmd uv

  # Optional structural enrichment (same as text mode).
  if [ "$PAGE_STRUCTURE" = true ] || [ "$DOC_STRUCTURE" = true ]; then
    ensure_helper "$READ_PDF_STRUCTURE_SCRIPT" "read_pdf_structure.py"
    local struct_json
    if ! struct_json=$(uv_run --with pymupdf4llm python "${READ_PDF_STRUCTURE_SCRIPT}" "$PDF"); then
      runtime_err "pymupdf4llm structure scan failed for: $PDF"
    fi

    if [ "$PAGE_STRUCTURE" = true ]; then
      PAGE_STRUCTURE_XML=$(uv_run python - "$struct_json" <<'PY'
import json
import sys

data = json.loads(sys.argv[1])
out = []
out.append("  <page-structure>")
for p in data.get("pages", []):
    idx = p.get("index")
    if idx is None:
        continue
    out.append(
        f'    <page index="{idx}" '
        f'has_text="{str(bool(p.get("has_text"))).lower()}" '
        f'word_count="{p.get("word_count", 0)}" '
        f'image_count="{p.get("image_count", 0)}" '
        f'table_count="{p.get("table_count", 0)}" />'
    )
out.append("  </page-structure>")
print("\n".join(out))
PY
)
    fi

    if [ "$DOC_STRUCTURE" = true ]; then
      DOC_STRUCTURE_XML=$(uv_run python - "$struct_json" <<'PY'
import json
import sys

def esc(val: str) -> str:
    return (
        val.replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
        .replace('"', "&quot;")
        .replace("'", "&apos;")
    )

data = json.loads(sys.argv[1])
out = []
out.append("  <doc-structure>")

out.append("    <bookmarks>")
for b in data.get("bookmarks", []):
    title = esc(str(b.get("title", "")))
    page = b.get("page")
    level = b.get("level")
    if page is None or level is None:
        continue
    out.append(f'      <bookmark title="{title}" page="{page}" level="{level}" />')
out.append("    </bookmarks>")

out.append("    <links>")
for l in data.get("links", []):
    ltype = l.get("type")
    from_page = l.get("from_page")
    if from_page is None or ltype not in {"internal", "external"}:
        continue
    if ltype == "external":
        uri = esc(str(l.get("uri", "")))
        out.append(f'      <link type="external" from_page="{from_page}" uri="{uri}" />')
    elif ltype == "internal":
        to_page = l.get("to_page")
        if to_page is None:
            continue
        out.append(f'      <link type="internal" from_page="{from_page}" to_page="{to_page}" />')
out.append("    </links>")

out.append("  </doc-structure>")
print("\n".join(out))
PY
      )
    fi
  fi

  ensure_helper "$READ_PDF_TEXT_SCRIPT" "read_pdf_text.py"

  local tmpdir
  tmpdir=$(mktemp -d -t read-pdf-toc.XXXXXX)
  local tmp_text="${tmpdir}/toc.md"
  local tmp_meta="${tmpdir}/toc_meta.json"

  local code=0
  if uv_run --with pymupdf4llm python "${READ_PDF_TEXT_SCRIPT}" \
    --filter toc \
    --toc-max-pages "$TOC_MAX_PAGES" \
    --meta-json-out "$tmp_meta" \
    "$PDF" >"$tmp_text"; then
    :
  else
    code=$?
    if [ "$code" -eq 4 ]; then
      rm -rf "$tmpdir"
      cat <<MSG
No TOC/Index/List pages matched by best-effort heuristics.

This is a best-effort regex/structure search and may miss a real Table of Contents / Índice / Index page.

Next steps:
- Read full text: read-pdf "$(printf '%s' "$PDF")"
- Or render images: read-pdf "$(printf '%s' "$PDF")" --as-images --pages "1-10"
MSG
      return 0
    fi
    runtime_err "pymupdf4llm (via uv) failed for: $PDF"
  fi

  if [ ! -s "$tmp_text" ]; then
    rm -rf "$tmpdir"
    cat <<MSG
No TOC/Index/List pages matched by best-effort heuristics.

This is a best-effort regex/structure search and may miss a real Table of Contents / Índice / Index page.

Next steps:
- Read full text: read-pdf "$(printf '%s' "$PDF")"
- Or render images: read-pdf "$(printf '%s' "$PDF")" --as-images --pages "1-10"
MSG
    return 0
  fi

  local toc_full_char_count
  toc_full_char_count=$(
    uv_run python - "$tmp_meta" <<'PY'
import json
import sys

with open(sys.argv[1], "r", encoding="utf-8") as f:
    data = json.load(f)

print(str(data.get("full_char_count", 0)))
PY
  )

  TOC_MATCHED_PAGES=$(
    uv_run python - "$tmp_meta" <<'PY'
import json
import sys

with open(sys.argv[1], "r", encoding="utf-8") as f:
    data = json.load(f)

pages = data.get("selected_pages") or []
print(",".join(str(p) for p in pages))
PY
  )

  TOC_EXTRACTION_XML=$(uv_run python - "$TOC_MATCHED_PAGES" "$TOC_MAX_PAGES" <<'PY'
import sys

def esc(val: str) -> str:
    return (
        val.replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
        .replace('"', "&quot;")
        .replace("'", "&apos;")
    )

matched_pages = sys.argv[1]
max_pages = sys.argv[2]
print(
    '  <toc-extraction best_effort="true" '
    f'max_pages="{esc(max_pages)}" '
    f'matched_pages="{esc(matched_pages)}" '
    'note="heuristic-only; may miss TOC/Index pages (including ones not matched by regex/heuristics)" />'
)
PY
)

  local char_count
  char_count=$(wc -c < "$tmp_text" | tr -d ' ')
  emit_metadata "$toc_full_char_count"
  emit_text_block "$tmp_text" "$char_count"
  rm -rf "$tmpdir"
}

raw_text_mode() {
  CONVERSION_ENGINE="pymupdf4llm"

  [ -f "$PDF" ] || runtime_err "PDF not found: $PDF"

  need_cmd uv
  ensure_helper "$READ_PDF_TEXT_SCRIPT" "read_pdf_text.py"

  if ! uv_run --with pymupdf4llm python "${READ_PDF_TEXT_SCRIPT}" "$PDF"; then
    runtime_err "pymupdf4llm (via uv) failed for: $PDF"
  fi
}

prime_cache_mode() {
  CONVERSION_ENGINE="uv"
  MODE="prime-cache"

  need_cmd uv

  local cache_dir
  cache_dir=$(resolve_uv_cache_dir)

  echo "Priming uv cache for ${TOOL_NAME} (cache_dir=${cache_dir})..." >&2
  echo "  - markitdown[pdf]" >&2
  echo "  - pymupdf" >&2
  echo "  - pymupdf4llm" >&2

  local old_offline="$READ_PDF_UV_OFFLINE"
  READ_PDF_UV_OFFLINE=0

  # Warm each optional engine explicitly so later offline/restricted runs don't need network.
  uv_run --with 'markitdown[pdf]' python - <<'PY'
from markitdown import MarkItDown

_ = MarkItDown()
print("ok: markitdown")
PY
  uv_run --with pymupdf python - <<'PY'
import fitz

print("ok: pymupdf")
PY
  uv_run --with pymupdf4llm --with pymupdf python - <<'PY'
import fitz
import pymupdf4llm

print("ok: pymupdf4llm")
PY

  READ_PDF_UV_OFFLINE="$old_offline"
  echo "Prime complete." >&2
}

toc_pages_mode() {
  CONVERSION_ENGINE="pymupdf"
  MODE="toc-pages"

  [ -f "$PDF" ] || runtime_err "PDF not found: $PDF"

  need_cmd uv
  ensure_helper "$READ_PDF_PAGE_CANDIDATES_SCRIPT" "read_pdf_page_candidates.py"

  gather_pdf_info "$PDF"

  if ! uv_run --with pymupdf python "${READ_PDF_PAGE_CANDIDATES_SCRIPT}" \
    --kind toc \
    --tool "$TOOL_NAME" \
    --tool-version "$VERSION" \
    --pdf-pages "$PDF_PAGES" \
    "$PDF"; then
    runtime_err "page candidate detection failed (toc-pages) for: $PDF"
  fi
}

table_pages_mode() {
  CONVERSION_ENGINE="pymupdf"
  MODE="table-pages"

  [ -f "$PDF" ] || runtime_err "PDF not found: $PDF"

  need_cmd uv
  ensure_helper "$READ_PDF_PAGE_CANDIDATES_SCRIPT" "read_pdf_page_candidates.py"

  gather_pdf_info "$PDF"

  if ! uv_run --with pymupdf python "${READ_PDF_PAGE_CANDIDATES_SCRIPT}" \
    --kind table \
    --tool "$TOOL_NAME" \
    --tool-version "$VERSION" \
    --pdf-pages "$PDF_PAGES" \
    "$PDF"; then
    runtime_err "page candidate detection failed (table-pages) for: $PDF"
  fi
}

chart_pages_mode() {
  CONVERSION_ENGINE="pymupdf"
  MODE="chart-pages"

  [ -f "$PDF" ] || runtime_err "PDF not found: $PDF"

  need_cmd uv
  ensure_helper "$READ_PDF_PAGE_CANDIDATES_SCRIPT" "read_pdf_page_candidates.py"

  gather_pdf_info "$PDF"

  if ! uv_run --with pymupdf python "${READ_PDF_PAGE_CANDIDATES_SCRIPT}" \
    --kind chart \
    --tool "$TOOL_NAME" \
    --tool-version "$VERSION" \
    --pdf-pages "$PDF_PAGES" \
    "$PDF"; then
    runtime_err "page candidate detection failed (chart-pages) for: $PDF"
  fi
}

search_mode() {
  CONVERSION_ENGINE="pymupdf"
  MODE="search"

  [ -f "$PDF" ] || runtime_err "PDF not found: $PDF"

  need_cmd uv
  ensure_helper "$READ_PDF_SEARCH_SCRIPT" "read_pdf_search.py"

  gather_pdf_info "$PDF"

  if ! uv_run --with pymupdf python "${READ_PDF_SEARCH_SCRIPT}" \
    --regex "$SEARCH_REGEX" \
    --context-words 50 \
    --tool "$TOOL_NAME" \
    --tool-version "$VERSION" \
    --pdf-pages "$PDF_PAGES" \
    "$PDF"; then
    runtime_err "search failed for: $PDF"
  fi
}

# ---------- Images mode helpers (ported from read-pdf-as-images) ----------

parse_pages() {
  local spec=$1
  local IFS=,
  local -a parts out
  read -r -a parts <<<"$spec"
  local part
  for part in "${parts[@]}"; do
    part=${part//[[:space:]]/}
    [ -z "$part" ] && continue
    if [[ "$part" =~ ^[0-9]+$ ]]; then
      out+=("$part")
    elif [[ "$part" =~ ^([0-9]+)-([0-9]+)$ ]]; then
      local a=${BASH_REMATCH[1]} b=${BASH_REMATCH[2]}
      if (( a<=b )); then
        local i
        for (( i=a; i<=b; i++ )); do out+=("$i"); done
      else
        err "Invalid range: $part (start>end)"
        usage >&2
        exit 2
      fi
    else
      err "Invalid page token: $part"
      usage >&2
      exit 2
    fi
  done
  printf '%s\n' "${out[@]}" | awk 'NF' | sort -n | uniq
}

group_contiguous() {
  awk 'BEGIN{prev=-1;start=-1}
       {cur=$1; if (start==-1){start=cur; prev=cur; next}
        if (cur==prev+1){prev=cur; next}
        printf "%d %d\n", start, prev; start=cur; prev=cur}
       END{ if (start!=-1) printf "%d %d\n", start, prev }'
}

image_dimensions_px() {
  local img=$1

  local dims=""
  if command -v file >/dev/null 2>&1; then
    local desc=""
    desc=$(file -b -- "$img" 2>/dev/null || true)
    if [ -n "$desc" ]; then
      dims=$(printf '%s' "$desc" | awk 'match($0, /([0-9]+)[[:space:]]*x[[:space:]]*([0-9]+)/, m) {print m[1], m[2]; exit}')
    fi
  fi

  if [ -z "$dims" ]; then
    if [[ "${PDF_PAGE_W_PTS:-}" =~ ^[0-9]+([.][0-9]+)?$ ]] && [[ "${PDF_PAGE_H_PTS:-}" =~ ^[0-9]+([.][0-9]+)?$ ]]; then
      dims=$(awk -v wpts="$PDF_PAGE_W_PTS" -v hpts="$PDF_PAGE_H_PTS" -v dpi="$DPI" 'BEGIN { w=(wpts/72.0)*dpi; h=(hpts/72.0)*dpi; printf "%d %d", int(w+0.5), int(h+0.5) }')
    fi
  fi

  if [ -z "$dims" ]; then
    return 1
  fi

  printf '%s\n' "$dims"
}

estimate_tokens_gpt5_high_detail() {
  local w=$1
  local h=$2
  awk -v w="$w" -v h="$h" -v base=70 -v tile=140 '
function ceil(x) { return (x == int(x)) ? x : int(x) + 1 }
BEGIN {
  max = (w > h) ? w : h
  s1 = (max > 2048) ? 2048.0 / max : 1.0
  w1 = w * s1
  h1 = h * s1
  min = (w1 < h1) ? w1 : h1
  s2 = 768.0 / min
  w2 = w1 * s2
  h2 = h1 * s2
  tiles = ceil(w2 / 512.0) * ceil(h2 / 512.0)
  tokens = base + tile * tiles
  printf "%d", tokens
}'
}

gemini3_image_tokens_for_dpi() {
  # Gemini 3 image token counts are based on media_resolution budgets (not DPI).
  # To keep stdout concise and deterministic, we select a single media_resolution
  # from the user-supplied --dpi as a best-effort heuristic.
  #
  # Source (as of 2026-01-13): https://ai.google.dev/gemini-api/docs/media-resolution
  #
  # Mapping heuristic:
  # - dpi <= 150  -> LOW    (280 tokens)
  # - 151..239    -> MEDIUM (560 tokens)
  # - >= 240      -> HIGH   (1120 tokens)
  local dpi=$1
  if (( dpi <= 150 )); then
    printf '%s %s\n' "MEDIA_RESOLUTION_LOW" "280"
  elif (( dpi < 240 )); then
    printf '%s %s\n' "MEDIA_RESOLUTION_MEDIUM" "560"
  else
    printf '%s %s\n' "MEDIA_RESOLUTION_HIGH" "1120"
  fi
}

images_mode() {
  CONVERSION_ENGINE="pdftoppm"

  [ -f "$PDF" ] || runtime_err "PDF not found: $PDF"

  need_cmd pdfinfo
  need_cmd pdftoppm

  gather_pdf_info "$PDF"

  # Validate format
  case "$FORMAT" in
    png|jpeg) :;;
    *)
      err "Unsupported --format: $FORMAT (png|jpeg)"
      usage >&2
      exit 2
      ;;
  esac

  # pdftoppm uses ".jpg" for JPEG output (even when invoked with -jpeg).
  # Keep the CLI surface as --format jpeg but normalize the expected file extension.
  local output_ext="$FORMAT"
  if [ "$FORMAT" = "jpeg" ]; then
    output_ext="jpg"
  fi

  if [ -z "$OUTDIR" ]; then
    local base_no_ext
    base_no_ext=${PDF_BASENAME%.*}
    OUTDIR="tmp/pdf_renders/$base_no_ext"
  fi
  mkdir -p -- "$OUTDIR"

  local -a pages=()
  if [ -n "$PAGES_SPEC" ]; then
    mapfile -t pages < <(parse_pages "$PAGES_SPEC")
  else
    local i
    for (( i=1; i<=PDF_PAGES; i++ )); do pages+=("$i"); done
  fi

  if ((${#pages[@]}==0)); then
    err "No pages selected"
    usage >&2
    exit 2
  fi

  local p
  for p in "${pages[@]}"; do
    if (( p<1 || p>PDF_PAGES )); then
      err "Page out of bounds: $p (1..$PDF_PAGES)"
      usage >&2
      exit 2
    fi
  done

  local pad
  local digits=${#PDF_PAGES}
  if (( digits<3 )); then pad=3; else pad=$digits; fi

  local fmtflag
  fmtflag="-$FORMAT"

  local -a grouped=()
  mapfile -t grouped < <(printf '%s\n' "${pages[@]}" | group_contiguous)
  local range
  for range in "${grouped[@]}"; do
    local start end
    read -r start end <<<"$range"
    pdftoppm "$fmtflag" -rx "$DPI" -ry "$DPI" -f "$start" -l "$end" -- "$PDF" "$OUTDIR/page" >/dev/null
  done

  local total_gpt5=0
  local pages_rendered=0

  for p in "${pages[@]}"; do
    local fname
    printf -v fname "%s/page-%0${pad}d.%s" "$OUTDIR" "$p" "$output_ext"
    if [ ! -f "$fname" ]; then
      local found=""
      local -a candidates=()
      printf -v candidates[0] "%s/page-%d.%s" "$OUTDIR" "$p" "$output_ext"
      printf -v candidates[1] "%s/page-%02d.%s" "$OUTDIR" "$p" "$output_ext"
      printf -v candidates[2] "%s/page-%03d.%s" "$OUTDIR" "$p" "$output_ext"
      local candidate
      for candidate in "${candidates[@]}"; do
        if [ -f "$candidate" ]; then
          found="$candidate"
          break
        fi
      done
      if [ -n "$found" ]; then
        mv -f -- "$found" "$fname"
      else
        runtime_err "Expected output missing: $fname"
      fi
    fi

    local w h
    if ! read -r w h < <(image_dimensions_px "$fname"); then
      runtime_err "Could not determine rendered image dimensions for: $fname"
    fi

    local gpt5_tokens
    gpt5_tokens=$(estimate_tokens_gpt5_high_detail "$w" "$h")

    total_gpt5=$(( total_gpt5 + gpt5_tokens ))
    pages_rendered=$(( pages_rendered + 1 ))

    printf '{"page":%d,"path":"%s","dpi":%d,"format":"%s","mode":"images","pdf_path":"%s","pdf_basename":"%s","tool":"%s","tool_version":"%s","engine":"%s"}\n' \
      "$p" \
      "$(json_escape "$fname")" \
      "$DPI" \
      "$FORMAT" \
      "$(json_escape "$PDF_PATH")" \
      "$(json_escape "$PDF_BASENAME")" \
      "$(json_escape "$TOOL_NAME")" \
      "$(json_escape "$VERSION")" \
      "$(json_escape "$CONVERSION_ENGINE")" >&2
  done

  local avg_gpt5
  avg_gpt5=$(awk -v t="$total_gpt5" -v n="$pages_rendered" 'BEGIN{ if(n<=0){printf "0"} else {printf "%.2f", t/n} }')

  local gemini_resolution gemini_tokens_per_image
  read -r gemini_resolution gemini_tokens_per_image < <(gemini3_image_tokens_for_dpi "$DPI")
  local gemini_total=$(( pages_rendered * gemini_tokens_per_image ))

  printf 'Token estimate (images only): gpt-5(detail=high) total=%d avg_per_page=%s; gemini-3*(%s, derived_from_dpi=%d) total=%d avg_per_page=%d\n' \
    "$total_gpt5" \
    "$avg_gpt5" \
    "$gemini_resolution" \
    "$DPI" \
    "$gemini_total" \
    "$gemini_tokens_per_image"
}

parse_args() {
  if (( $#==0 )); then
    usage >&2
    exit 2
  fi

  while (( $#>0 )); do
    case "$1" in
      -h|--help)
        usage
        exit 0
        ;;
      -V|--version)
        echo "${TOOL_NAME} ${VERSION}"
        exit 0
        ;;
      --prime-cache)
        if [ "$MODE" != "text" ]; then
          err "Only one mode may be specified"
          usage >&2
          exit 2
        fi
        MODE="prime-cache"
        shift
        ;;
      --as-text)
        # Explicit alias of --as-text-fast (documented in --help).
        if [ "$MODE" != "text" ]; then
          err "Only one mode may be specified"
          usage >&2
          exit 2
        fi
        MODE="text"
        TEXT_ENGINE="markitdown"
        shift
        ;;
      --as-text-fast)
        if [ "$MODE" != "text" ]; then
          err "Only one mode may be specified"
          usage >&2
          exit 2
        fi
        MODE="text"
        TEXT_ENGINE="markitdown"
        shift
        ;;
      --as-text-precise-layout-slow)
        if [ "$MODE" != "text" ]; then
          err "Only one mode may be specified"
          usage >&2
          exit 2
        fi
        MODE="text"
        TEXT_ENGINE="pymupdf4llm"
        shift
        ;;
      --as-raw-text)
        if [ "$MODE" != "text" ]; then
          err "Only one mode may be specified"
          usage >&2
          exit 2
        fi
        MODE="raw"
        shift
        ;;
      --as-images)
        if [ "$MODE" != "text" ]; then
          err "Only one mode may be specified"
          usage >&2
          exit 2
        fi
        MODE="images"
        shift
        ;;
      --toc)
        if [ "$MODE" != "text" ]; then
          err "Only one mode may be specified"
          usage >&2
          exit 2
        fi
        MODE="toc"
        shift
        ;;
      --toc-pages)
        if [ "$MODE" != "text" ]; then
          err "Only one mode may be specified"
          usage >&2
          exit 2
        fi
        MODE="toc-pages"
        shift
        ;;
      --table-pages)
        if [ "$MODE" != "text" ]; then
          err "Only one mode may be specified"
          usage >&2
          exit 2
        fi
        MODE="table-pages"
        shift
        ;;
      --chart-pages)
        if [ "$MODE" != "text" ]; then
          err "Only one mode may be specified"
          usage >&2
          exit 2
        fi
        MODE="chart-pages"
        shift
        ;;
      --search)
        if [ "$MODE" != "text" ]; then
          err "Only one mode may be specified"
          usage >&2
          exit 2
        fi
        MODE="search"
        shift || { usage >&2; exit 2; }
        SEARCH_REGEX=${1:-}
        if [ -z "$SEARCH_REGEX" ]; then
          err "--search requires a <regex> argument"
          usage >&2
          exit 2
        fi
        shift
        ;;
      --page-structure)
        PAGE_STRUCTURE=true
        shift
        ;;
      --doc-structure)
        DOC_STRUCTURE=true
        shift
        ;;
      --pages)
        if [ "$MODE" != "images" ]; then
          err "--pages is only valid with --as-images"
          usage >&2
          exit 2
        fi
        shift || { usage >&2; exit 2; }
        PAGES_SPEC=${1:-}
        shift
        ;;
      --dpi)
        if [ "$MODE" != "images" ]; then
          err "--dpi is only valid with --as-images"
          usage >&2
          exit 2
        fi
        shift || { usage >&2; exit 2; }
        DPI=${1:-}
        shift
        ;;
      --format)
        if [ "$MODE" != "images" ]; then
          err "--format is only valid with --as-images"
          usage >&2
          exit 2
        fi
        shift || { usage >&2; exit 2; }
        FORMAT=${1:-}
        shift
        ;;
      --outdir)
        if [ "$MODE" != "images" ]; then
          err "--outdir is only valid with --as-images"
          usage >&2
          exit 2
        fi
        shift || { usage >&2; exit 2; }
        OUTDIR=${1:-}
        shift
        ;;
      --*)
        err "Unknown flag: $1"
        usage >&2
        exit 2
        ;;
      *)
        if [ -z "$PDF" ]; then
          PDF=$1
        else
          err "Unexpected extra argument: $1"
          usage >&2
          exit 2
        fi
        shift
        ;;
    esac
  done

  if [ "$MODE" = "prime-cache" ]; then
    if [ -n "${PDF:-}" ]; then
      err "--prime-cache does not take a <pdf> argument"
      usage >&2
      exit 2
    fi
    return 0
  fi

  if [ -z "${PDF:-}" ]; then
    err "Missing <pdf> argument"
    usage >&2
    exit 2
  fi
}

main() {
  parse_args "$@"
  case "$MODE" in
    prime-cache) prime_cache_mode ;;
    text) text_mode ;;
    toc) toc_mode ;;
    raw) raw_text_mode ;;
    images) images_mode ;;
    toc-pages) toc_pages_mode ;;
    table-pages) table_pages_mode ;;
    chart-pages) chart_pages_mode ;;
    search) search_mode ;;
    *)
      runtime_err "Unknown mode: $MODE"
      ;;
  esac
}

main "$@"
